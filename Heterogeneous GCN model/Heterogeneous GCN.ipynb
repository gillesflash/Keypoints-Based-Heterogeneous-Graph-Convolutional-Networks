{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "exc_feat_path = './data/train/feat/exc/'\n",
    "dum_feat_path = './data/train/feat/dum/'\n",
    "cos_feat_path = './data/train/feat/cos/'\n",
    "\n",
    "exc_edge_path = './data/train/edge/exc/'\n",
    "dum_edge_path = './data/train/edge/dum/'\n",
    "cos_edge_path = './data/train/edge/cos/'\n",
    "\n",
    "\n",
    "exc_edge_list = glob.glob(exc_edge_path + '*.txt')\n",
    "dum_edge_list = glob.glob(dum_edge_path + '*.txt')\n",
    "cos_edge_list = glob.glob(cos_edge_path + '*.txt')\n",
    "\n",
    "exc_feat_list = glob.glob(exc_feat_path+'*.txt')\n",
    "dum_feat_list = glob.glob(dum_feat_path+'*.txt')\n",
    "cos_feat_list = glob.glob(cos_feat_path+'*.txt')\n",
    "\n",
    "labels = pd.read_csv('./data/labels.txt', header=None, sep=' ').values\n",
    "\n",
    "def create_graph(n):\n",
    "\n",
    "    exc_edge = pd.read_csv(exc_edge_list[n], sep=',', header=None).to_numpy()  \n",
    "    dum_edge = pd.read_csv(dum_edge_list[n], sep=',', header=None).to_numpy()\n",
    "    cos_edge = pd.read_csv(cos_edge_list[n], sep=',', header=None).to_numpy()\n",
    "    \n",
    "\n",
    "    exc_src = exc_edge[:, 0]\n",
    "    exc_dst = exc_edge[:, 1]\n",
    "\n",
    "    dum_src = dum_edge[:, 0]\n",
    "    dum_dst = dum_edge[:, 1]\n",
    "\n",
    "    cos_src = cos_edge[:, 0]\n",
    "    cos_dst = cos_edge[:, 1]\n",
    "    # print(feature_data_list[n])\n",
    "    # Read the entire feature data from the file\n",
    "    \n",
    "    exc_feat = pd.read_csv(exc_feat_list[n], sep='\\t', header=None).to_numpy()\n",
    "    dum_feat = pd.read_csv(dum_feat_list[n], sep='\\t', header=None).to_numpy()\n",
    "    cos_feat = pd.read_csv(cos_feat_list[n], sep='\\t', header=None).to_numpy()\n",
    "\n",
    "    # print(exc_feat.shape)\n",
    "\n",
    "    # Define number of nodes for each type\n",
    "\n",
    "\n",
    "    hetero_graph = dgl.heterograph({\n",
    "        ('exc', 'inexc', 'exc'): (exc_src, exc_dst),\n",
    "        ('exc', 'outexc', 'exc'): (exc_dst, exc_src),\n",
    "        ('dum', 'indum', 'dum'): (dum_src, dum_dst), \n",
    "        ('dum', 'outdum', 'dum'): (dum_dst, dum_src),\n",
    "        ('cos', 'incos', 'cos'): (cos_src, cos_dst), \n",
    "        ('cos', 'outcos', 'cos'): (cos_dst, cos_src), \n",
    "    })\n",
    "    hetero_graph = hetero_graph.to(device)\n",
    "    hetero_graph.nodes['exc'].data['feat'] = torch.tensor(exc_feat, dtype=torch.float32).to(device)\n",
    "    hetero_graph.nodes['dum'].data['feat'] = torch.tensor(dum_feat, dtype=torch.float32).to(device)\n",
    "    hetero_graph.nodes['cos'].data['feat'] = torch.tensor(cos_feat, dtype=torch.float32).to(device)\n",
    "\n",
    "    label = labels[n]\n",
    "    return hetero_graph, torch.LongTensor(label).to(device)\n",
    "\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(in_feats, hid_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(hid_feats, out_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: F.relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "        return h\n",
    "\n",
    "class HeteroClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, n_classes, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rgcn1 = RGCN(in_dim, hidden_dim, hidden_dim, rel_names)\n",
    "        self.rgcn2 = RGCN(hidden_dim, hidden_dim, hidden_dim, rel_names)\n",
    "        self.classify = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, g):\n",
    "        h = g.ndata['feat']\n",
    "        h = self.rgcn1(g, h)\n",
    "        h = self.rgcn2(g, h)\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            hg = 0\n",
    "            for ntype in g.ntypes:\n",
    "                hg = hg + dgl.mean_nodes(g, 'h', ntype=ntype)\n",
    "            return self.classify(hg)\n",
    "\n",
    "# print(dataset[0])\n",
    "\n",
    "def collate(samples):\n",
    "    # graphs, labels = map(list, zip(*samples))\n",
    "    graphs, labels = zip(*samples)\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    batched_labels = torch.tensor(labels)\n",
    "    return batched_graph, batched_labels\n",
    "\n",
    "\n",
    "dataset = [create_graph(n) for n in range(len(exc_feat_list))]\n",
    "\n",
    "\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.1, random_state=137)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    collate_fn=collate,\n",
    "    drop_last=False,\n",
    "    shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=256,\n",
    "    collate_fn=collate,\n",
    "    drop_last=False)\n",
    "\n",
    "etypes = dataset[0][0].etypes\n",
    "# print(etypes)\n",
    "model = HeteroClassifier(3, 256, 4, etypes).to(device)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "loss_values = []\n",
    "acc_values = []\n",
    "\n",
    "for epoch in range(1000):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model(batched_graph)\n",
    "        loss = F.cross_entropy(logits, labels.squeeze(-1))\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch {epoch}, Training Loss: {train_loss / len(train_dataloader)}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "for epoch in range(1000):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model(batched_graph)\n",
    "        loss = F.cross_entropy(logits, labels.squeeze(-1))\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch {epoch}, Training Loss: {train_loss / len(train_dataloader)}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batched_graph, labels in val_dataloader:\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits = model(batched_graph)\n",
    "            loss = F.cross_entropy(logits, labels.squeeze(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            val_acc += (predicted == labels.squeeze(-1)).sum().item() / len(labels)\n",
    "\n",
    "        print(f'Epoch {epoch}, Validation Loss: {val_loss / len(val_dataloader)}, Validation Accuracy: {val_acc / len(val_dataloader)}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_dgl_00",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
